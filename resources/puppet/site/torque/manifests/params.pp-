class torque::params {
  $version_cache  = latest
  $version_torque = '2.4.161'

#  if $::hostname == 'wagap' {
#    $version_torque = '2.4.97'
#  } else {
#    $version_torque = '2.4.96'
#  }

  $pkg_version_torque_erb = $::operatingsystem ? {
    debian  => "<%= @version %>+deb${::lsbmajdistrelease}",
    default => latest
  }

  $server_name = 'wagap.cerit-sc.cz'
  $client_name = 'wagap.cerit-sc.cz'

  # pbs_cache
  $cache_opts  = "-A $server_name -I 147.251.* -I 127.0.0.1 -D 10 -m scratch_local -m scratch_ssd -m scratch_pool -m scratch_leftover -m fairshare.default -m mapping -m gpu_allocation -m dynamic_resources -m phys_cluster -m magrathea  -m pbsload -m machine_cluster -m cluster -m host -p /var/run/pbs_cache.pid"

  # pbs_server
  $server_acct_enabled = true
  $server_acct_command = '/software/metaacct-1.0/pbs_accounting_torque.sh'
  $server_sysconfig = '
ulimit -c unlimited
ulimit -n 10000
ulimit -H -n 10000
'

  # pbs_mom
  $mom_single_job_is_excl = true
  $mom_ign_list = ['vmem']
  $mom_enablemomrestart = true
  $mom_simulate_kill = false
  $mom_max_conn_timeout_micro_sec = 4000000
  $mom_config = {
    'node_check_script'   => '/var/spool/torque/mom_scripts/node_check_script',
    'node_check_interval' => '5,jobstart,jobend',
    'down_on_error'       => true,
    'cgroup_path_cpu'     => $::cgroup_path ? {
      undef   => $::cgroup_path,
      default => "${::cgroup_path}/cpu"
    },
    'cgroup_path_mem'     => $::cgroup_path ? {
      undef   => $::cgroup_path,
      default => "${::cgroup_path}/memory"
    },
    'usecp'               => [
      '*:/storage /storage',
      '*.cerit-sc.cz:/mnt /mnt'
    ],
  }

  $mom_sysconfig = '
fail() {
  MSG=$1
  echo "Error: $MSG" >&2
  logger -t pbs_mom -p crit "health check failed: $MSG"
  exit 1
}

health_check() {
  # scheduled system reboot or maintenance
  if [ -f /run/systemd/shutdown/scheduled ] || \
     [ -f /etc/nologin ] || \
     [ -f /var/run/nologin ] || \
     [ -f /var/run/shutdown.pid ];
  then
    fail "Pending system reboot or maintenance"
  fi

  CORES=$(grep processor /proc/cpuinfo | wc -l)
  LOAD5=$(cut -d" " -f2 /proc/loadavg)
  RATIO=1.3
  if [ $(echo "$LOAD5 > ($CORES * $RATIO)" | bc) = "1" ]; then
    fail "High load5 $LOAD5 (more than $CORES cores * $RATIO)"
  fi

  ( set +m; timeout -s KILL 1.5 ibv_devinfo ) &>/dev/null
  if [ $? -eq 137 ]; then
    fail "Broken Infiniband"
  fi

  # check mounted AFS
  if ! [ -d /afs/ics.muni.cz/software/ ]; then
    fail "AFS not available"
  fi

  # check for META realm in krb5.conf
  if ! grep -q META /etc/krb5.conf; then
    fail "Missing META realm in krb5.conf"
  fi

  # check free space on root volume
  ROOT_FREE=`df -P / | tail -1 | awk \'{ print $4 }\'`
  if [ ${ROOT_FREE} -lt 409600 ]; then
    fail "Not enough free space (${ROOT_FREE}) on root volume"
  fi

#TODO: kontrolovat expirovane ucty
#  # check correctly mounted /home
#  NO_USERS=$(timeout 10 ls -la /home/ 2>/dev/null | egrep "nobody|nogroup" | wc -l)
#  if [ "${NO_USERS}" -gt 100 ]; then
#    fail "Too many nobody/nogroup (${NO_USERS}) in /home"
#  fi


  HOME_COUNT=$(timeout 10 ls /home/ 2>/dev/null | wc -l)
  if [ "${HOME_COUNT}" -lt 500 ]; then
    fail "Not enough directories (${HOME_COUNT}) in /home"
  fi

  # check users
  USERS_COUNT=$(getent passwd | wc -l)
  if [ "${USERS_COUNT}" -lt 500 ]; then
    fail "Not enough users (${USERS_COUNT})"
  fi

  # check correctly mounted /scratch
  SCRATCH_COUNT=$(ls -la /scratch/ 2>/dev/null | wc -l)
  if [ "${SCRATCH_COUNT}" -lt 500 ]; then
    fail "Not enough directories (${SCRATCH_COUNT}) in /scratch"
  fi

  # check if scratch is mounted r/w
  for SCRATCH_DIR in /scratch; do
    if [ -d $SCRATCH_DIR ]; then
      FILE=`mktemp ${SCRATCH_DIR}/.pbs_mom.XXXXX 2>/dev/null`
      if [ "x${FILE}" == "x" ]; then
        fail "Write test to ${SCRATCH_DIR} failed"
      fi
      unlink "${FILE}"
    fi
  done
}

case "$1" in
  start|restart|"")
    # always force Perun propagation
    if [ -x /etc/init.d/perun_propagate ]; then
      /etc/init.d/perun_propagate start || exit 1
    fi

    health_check
    ;;

  health|check|health-check|healthcheck)
    ( health_check ) 2>&1 &

    TIMEOUT=20
    while [ $TIMEOUT -gt 0 ]; do
      kill -0 $! &>/dev/null || exit 0
      TIMEOUT=$[$TIMEOUT-1]
      sleep 1
    done

    echo "Error: health check timed out"
    exit 1
    ;;
esac

# virtual memory
ulimit -v unlimited

# max memory size
ulimit -m unlimited

# max locked memory
ulimit -l unlimited

# core file size
ulimit -c unlimited

# open files
ulimit -H -n 40000
'

  # pbs_sched
  $sched_service = 'pbs_sched'
  $sched_conf_name = '/var/spool/torque/sched_priv/sched_config'
  $sched_config = {
    'local_server'             => {value => $server_name},
    'slave_server'             => {value => 'arien.ics.muni.cz'},
    'by_queue'                 => {all   => 'False'},
    'fair_share'               => {all   => 'True'},
    'fair_share_with_priority' => {all   => 'True'},
    'help_starving_jobs'       => {all   => 'True'},
    'sort_by'                  => {all   => 'no_sort'},
    'log_filter'               => {value => '256'} #no debug
  }
  $sched_sysconfig = '
ulimit -c unlimited
'

  # pbs_web_proxy
  $web_proxy_pkg_version  = latest
  $web_proxy_webroot      = '/srv/pbs_web_proxy'
  $web_proxy_port         = 6666

  # Torque MOM node default properties
  $torque_node_purge        = true
  $node_network      = getvar("::network_${::network_primary_interface}")
  $node_netmask      = getvar("::netmask_${::network_primary_interface}")
  $torque_node_np           = torque_node_np()
  $torque_node_properties   = torque_node_props()
  $torque_node_machine_spec = 10.0000
  $torque_node_ntype        = 'cluster'
  $torque_node_priority     = 100
  $torque_node_order        = 10
  $node_room         = undef
  $node_city         = $::city
  $node_infiniband   = $::city
  $node_home         = undef
  $torque_node_membership   = inclusive
  $torque_node_provider     = 'parsed'
}
